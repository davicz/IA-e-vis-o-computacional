{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f620ebe8",
      "metadata": {
        "id": "f620ebe8"
      },
      "source": [
        "# Aula 6: Introdu√ß√£o √† Engenharia de Prompt\n",
        "\n",
        "**Objetivo:** Implementar um classificador de emails simples usando um LLM (gpt-4o-mini) e os 4 componentes fundamentais da Engenharia de Prompt.\n",
        "\n",
        "> **Conceitos-chave abordados**:\n",
        "> - **Engenharia de Prompt**: A t√©cnica de estruturar o texto de entrada (prompt) para obter a sa√≠da desejada de um Modelo de Linguagem.\n",
        "> - **Componentes do Prompt**: O uso de tags (Persona, Task, Instructions, Output) para organizar e definir o comportamento do modelo.\n",
        "> - **Classifica√ß√£o Zero-Shot**: A capacidade de um LLM classificar textos em categorias que ele n√£o foi *explicitamente* treinado para, apenas seguindo instru√ß√µes.\n",
        "\n",
        "**Refer√™ncias**\n",
        "\n",
        "- [Documenta√ß√£o da API da OpenAI](https://platform.openai.com/docs/api-reference)\n",
        "- [Guia de Engenharia de Prompt (OpenAI)](https://platform.openai.com/docs/guides/prompt-engineering)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìã Fluxo do exerc√≠cio\n",
        "\n",
        "1.  **Configurar o ambiente** inserindo a `OPENAI_API_KEY`.\n",
        "2.  **Analisar a Tarefa Pr√°tica** (Classificador de Email).\n",
        "3.  **Completar os 4 componentes do prompt** (`aluno_persona`, `aluno_task`, `aluno_instructions`, `aluno_output`) na √°rea indicada.\n",
        "4.  **Executar o script de valida√ß√£o** para testar seu prompt contra 4 emails de exemplo e verificar se todos s√£o classificados corretamente."
      ],
      "metadata": {
        "id": "b3QloMvCmbL5"
      },
      "id": "b3QloMvCmbL5"
    },
    {
      "cell_type": "markdown",
      "id": "52b6f76d",
      "metadata": {
        "id": "52b6f76d"
      },
      "source": [
        "## ‚öôÔ∏è 1. Ambiente e Depend√™ncias (API)\n",
        "\n",
        "Preencha sua **API Key** da OpenAI. Voc√™ pode usar a vari√°vel de ambiente `OPENAI_API_KEY` ou inseri-la com seguran√ßa via `getpass`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5c049e21",
      "metadata": {
        "id": "5c049e21",
        "outputId": "4aaa7860-535e-43c1-fac2-df3de90b0dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite sua OPENROUTER_API_KEY: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Vari√°vel de ambiente OPENROUTER_API_KEY definida.\n",
            "SDK detectado. Modelo: openai/gpt-4o-mini via OpenRouter\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"\"\n",
        "# Entrada segura\n",
        "try:\n",
        "  from getpass import getpass\n",
        "except ImportError:\n",
        "  print(\"Aviso: M√≥dulo getpass n√£o encontrado, a chave ficar√° vis√≠vel.\")\n",
        "  getpass = input\n",
        "\n",
        "# 1) Tente ler da vari√°vel de ambiente (OpenRouter usa OPENROUTER_API_KEY)\n",
        "api_key = os.environ.get(\"OPENROUTER_API_KEY\", \"\").strip()\n",
        "\n",
        "# 2) Se n√£o houver, pe√ßa ao usu√°rio (input seguro)\n",
        "if not api_key and getpass is not None:\n",
        "    api_key = getpass(\"Digite sua OPENROUTER_API_KEY: \").strip()\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = api_key\n",
        "    print(\"Vari√°vel de ambiente OPENROUTER_API_KEY definida.\")\n",
        "else:\n",
        "    print(\"Vari√°vel de ambiente OPENROUTER_API_KEY encontrada.\")\n",
        "\n",
        "# Se ainda assim n√£o houver api, acuse um erro\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"API key ausente. Defina OPENROUTER_API_KEY ou insira via getpass.\")\n",
        "\n",
        "# OpenRouter base URL\n",
        "base_url = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "# Compatibilidade com vers√µes do SDK - configurando para OpenRouter\n",
        "client = None\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=base_url,\n",
        "    default_headers={\n",
        "        \"HTTP-Referer\": \"https://github.com/openrouter/openrouter\",  # Opcional: para tracking\n",
        "        \"X-Title\": \"Teste OpenRouter\",  # Opcional: nome da aplica√ß√£o\n",
        "    }\n",
        ")\n",
        "\n",
        "# Modelo dispon√≠vel no OpenRouter (pode usar modelos de diferentes provedores)\n",
        "# Exemplos: \"openai/gpt-4o-mini\", \"anthropic/claude-3-haiku\", \"meta-llama/llama-3.1-8b-instruct\"\n",
        "MODEL = \"openai/gpt-4o-mini\"  # Usando o mesmo modelo atrav√©s do OpenRouter\n",
        "print(f\"SDK detectado. Modelo: {MODEL} via OpenRouter\")\n",
        "\n",
        "# Utilit√°rios para chamadas e exibi√ß√£o\n",
        "def chat_complete(messages, temperature: float = 0.2, max_tokens: int = 300) -> str:\n",
        "    \"\"\"Chama o modelo com a lista de mensagens no formato [{'role': 'user'|'system'|'assistant', 'content': '...'}].\n",
        "    Retorna apenas o conte√∫do de texto da √∫ltima resposta.\n",
        "\n",
        "    Atrav√©s do OpenRouter, voc√™ pode usar modelos de diferentes provedores:\n",
        "    - OpenAI: \"openai/gpt-4o-mini\", \"openai/gpt-4\", \"openai/gpt-3.5-turbo\"\n",
        "    - Anthropic: \"anthropic/claude-3-haiku\", \"anthropic/claude-3-sonnet\"\n",
        "    - Meta: \"meta-llama/llama-3.1-8b-instruct\", \"meta-llama/llama-3.1-70b-instruct\"\n",
        "    - Google: \"google/gemini-pro\", \"google/gemini-flash\"\n",
        "    - Mistral: \"mistralai/mistral-7b-instruct\"\n",
        "\n",
        "    Para trocar o modelo, altere a vari√°vel MODEL acima.\n",
        "    \"\"\"\n",
        "    global client, MODEL\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "        )\n",
        "        return resp.choices[0].message.content or \"\"\n",
        "    except Exception as e:\n",
        "        return f\"[ERRO] {type(e).__name__}: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f683f7",
      "metadata": {
        "id": "c0f683f7"
      },
      "source": [
        "## ‚úâÔ∏è 2. Atividade Pr√°tica ‚Äî **Classificador de Email** (Preencha e Execute)\n",
        "\n",
        "Usando os **4 componentes**, crie um **prompt** para gerar um **sistema de an√°lise de emails**.\n",
        "- Sa√≠da deve ser **texto puro**, contendo apenas o motivo do email, que pode ser:\n",
        "  - **Quest√£o T√©cnica**\n",
        "  - **Problema de Faturamento**\n",
        "  - **Feedback de Produto**\n",
        "  - **Desconhecido** (em caso de d√∫vida)\n",
        "\n",
        "Ap√≥s definir o conte√∫do das tags,\n",
        "\n",
        "> **SE√á√ÉO PARA O ALUNO PREENCHER:** edite as vari√°veis abaixo (**persona**, **task**, **instructions**, **output**). Depois, execute a c√©lula para chamar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a0037aa1",
      "metadata": {
        "id": "a0037aa1",
        "outputId": "39b3dc9f-8fb3-4dad-fd7c-b146cf21a1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Classifica√ß√£o do Email 1: (esperado / obtido) = (Quest√£o T√©cnica / Quest√£o T√©cnica).\n",
            "‚úÖ Classifica√ß√£o do Email 2: (esperado / obtido) = (Problema de Faturamento / Problema de Faturamento).\n",
            "‚úÖ Classifica√ß√£o do Email 3: (esperado / obtido) = (Feedback de Produto / Feedback de Produto).\n",
            "‚úÖ Classifica√ß√£o do Email 4: (esperado / obtido) = (Desconhecido / Desconhecido).\n",
            "‚úÖ Todos os emails foram classificados corretamente!\n"
          ]
        }
      ],
      "source": [
        "from textwrap import dedent\n",
        "\n",
        "# ======== √ÅREA EDIT√ÅVEL PELO ALUNO ========\n",
        "aluno_persona = \"voc√™ √© um sistema de classifica√ß√£o de email\"\n",
        "aluno_task = \"verificar o que tem no <context>\"\n",
        "aluno_instructions = \"\"\"verificar se o email cabe em algum dos tipos\n",
        "\"Quest√£o T√©cnica\", \"Problema de Faturamento\", \"Feedback de Produto\", \"Desconhecido\"\"\"\n",
        "aluno_output = \"Retorne apenas o nome exato da categoria, sem nenhuma outra palavra.\"\n",
        "\n",
        "# ==========================================\n",
        "\n",
        "# Exemplo de emails\n",
        "emails = [\n",
        "  (\"\"\"\n",
        "  Assunto: Erro ao tentar fazer login\n",
        "\n",
        "  Ol√°,\n",
        "\n",
        "  Estou enfrentando um problema para acessar minha conta ‚Äî toda vez que tento fazer login, aparece uma mensagem dizendo que meu usu√°rio n√£o existe. J√° tentei redefinir a senha, mas nada mudou.\n",
        "\n",
        "  Poderiam verificar, por favor?\n",
        "\n",
        "  Obrigado,\n",
        "  Rodrigo\n",
        "  \"\"\", \"Quest√£o T√©cnica\"),\n",
        "  (\"\"\"\n",
        "  Assunto: Cobran√ßa duplicada na fatura de outubro\n",
        "\n",
        "  Prezados,\n",
        "\n",
        "  Notei que minha fatura deste m√™s apresenta dois d√©bitos referentes ao mesmo servi√ßo. Poderiam confirmar se houve cobran√ßa duplicada e realizar o estorno?\n",
        "\n",
        "  Atenciosamente,\n",
        "  Fernanda\n",
        "  \"\"\", \"Problema de Faturamento\"),\n",
        "  (\"\"\"\n",
        "  Assunto: Sugest√£o de melhoria no painel de relat√≥rios\n",
        "\n",
        "  Ol√° equipe,\n",
        "\n",
        "  Tenho gostado bastante da nova interface, mas senti falta de uma op√ß√£o para exportar relat√≥rios em CSV diretamente do painel. Acredito que isso facilitaria muito o trabalho do time.\n",
        "\n",
        "  Abra√ßos,\n",
        "  Marcelo\n",
        "  \"\"\", \"Feedback de Produto\"),\n",
        "  (\"\"\"\n",
        "  Assunto: Parceria para evento acad√™mico\n",
        "\n",
        "  Boa tarde,\n",
        "\n",
        "  Estou organizando um semin√°rio sobre inova√ß√£o e gostaria de saber se a empresa teria interesse em participar como apoiadora ou palestrante.\n",
        "\n",
        "  Fico √† disposi√ß√£o para conversar melhor.\n",
        "\n",
        "  Cordialmente,\n",
        "  Luana\n",
        "  \"\"\", \"Desconhecido\"),\n",
        "]\n",
        "\n",
        "wrong_emails = []\n",
        "\n",
        "for (index, (email, categoria_esperada)) in enumerate(emails, start=1):\n",
        "\n",
        "    prompt_atividade = dedent(f\"\"\"\n",
        "    <persona>{aluno_persona}</persona>\n",
        "    <task>{aluno_task}</task>\n",
        "    <instructions>{aluno_instructions}</instructions>\n",
        "    <output>{aluno_output}</output>\n",
        "    <context>\n",
        "    Email:\n",
        "    {email}\n",
        "    </context>\n",
        "    \"\"\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt_atividade}\n",
        "    ]\n",
        "\n",
        "    resposta_obtida = chat_complete(messages, temperature=0.1, max_tokens=50) # Reduzi max_tokens e temperature para classifica√ß√£o\n",
        "\n",
        "    # Agora validamos se a resposta √© uma das categorias esperadas (aproximado, pois o modelo pode variar a capitaliza√ß√£o ou adicionar espa√ßos)\n",
        "    categorias_validas = [\"Quest√£o T√©cnica\", \"Problema de Faturamento\", \"Feedback de Produto\", \"Desconhecido\"]\n",
        "\n",
        "    # Flag de corretude\n",
        "    resposta_correta = categoria_esperada.lower() == resposta_obtida.lower()\n",
        "    if not resposta_correta:\n",
        "        wrong_emails.append(index)\n",
        "\n",
        "    # Defina um caractere de status de corretude\n",
        "    result_char = \"‚úÖ\" if resposta_correta else \"‚ùå\"\n",
        "\n",
        "    print(f\"{result_char} Classifica√ß√£o do Email {index}: (esperado / obtido) = ({categoria_esperada} / {resposta_obtida}).\")\n",
        "\n",
        "if len(wrong_emails) == 0:\n",
        "    print(\"‚úÖ Todos os emails foram classificados corretamente!\")\n",
        "else:\n",
        "    print(f\"‚ùå Os seguintes emails foram classificados erroneamente: {wrong_emails}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Resumo da Tarefa do Aluno\n",
        "\n",
        "O objetivo √© criar um prompt de classifica√ß√£o de emails usando os 4 componentes-chave. Para isso, complete as quatro tarefas no script acima:\n",
        "\n",
        "1.  **Definir Persona**: Na c√©lula acima, defina `aluno_persona` para dizer ao modelo qual √© o seu papel (ex: \"Voc√™ √© um sistema de classifica√ß√£o...\").\n",
        "2.  **Definir Tarefa (Task)**: Defina `aluno_task` para explicar o objetivo principal (ex: \"Classificar o email em uma das 4 categorias...\").\n",
        "3.  **Definir Instru√ß√µes (Instructions)**: Defina `aluno_instructions` para dar regras espec√≠ficas (ex: \"Responda apenas com a categoria\", \"N√£o inclua explica√ß√µes\").\n",
        "4.  **Definir Formato de Sa√≠da (Output)**: Defina `aluno_output` para refor√ßar o formato exato da resposta (ex: \"Apenas o nome da categoria...\")."
      ],
      "metadata": {
        "id": "LpzyqVw6l_9o"
      },
      "id": "LpzyqVw6l_9o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß∑ Dicas e Notas\n",
        "\n",
        "- **Chave de API**: Se voc√™ receber um erro de autentica√ß√£o, verifique se sua `OPENAI_API_KEY` foi inserida corretamente na primeira c√©lula de c√≥digo.\n",
        "- **Modelo**: Estamos usando o `gpt-4o-mini`, que √© r√°pido e eficiente para tarefas de classifica√ß√£o.\n",
        "- **Temperatura**: Note que a fun√ß√£o `chat_complete` usa `temperature=0.1`. Uma temperatura baixa √© ideal para tarefas de classifica√ß√£o, pois queremos a resposta mais prov√°vel e menos criativa.\n",
        "- **A Tag `<output>`**: A tag `<output>` √© crucial. Ela ajuda a garantir que o modelo n√£o adicione texto extra, como \"Claro, a categoria √©: Problema de Faturamento.\" Ele responder√° apenas \"Problema de Faturamento.\""
      ],
      "metadata": {
        "id": "lmtp3q4smDge"
      },
      "id": "lmtp3q4smDge"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}